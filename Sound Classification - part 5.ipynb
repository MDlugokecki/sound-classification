{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e4816b",
   "metadata": {},
   "source": [
    "<h1> Sound Classification - part 5 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143d646e",
   "metadata": {},
   "source": [
    "In this part we will ensamble our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b63f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ee13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f31081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading saved X (features) and Y (labels) from files ()\n",
    "# mfcc features from part 1\n",
    "with open('part1_X.pickle', 'rb') as f:\n",
    "            X_mfcc = pickle.load(f)\n",
    "\n",
    "# other features from part 3\n",
    "with open('part3_X.pickle', 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "with open('part3_Y.pickle', 'rb') as f:\n",
    "            Y = pickle.load(f)\n",
    "\n",
    "# getting all features together\n",
    "X_all = pd.concat([X, X_mfcc], axis=1)\n",
    "\n",
    "# read metadata writen to file in part 1\n",
    "with open('part1_df.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea735e9f",
   "metadata": {},
   "source": [
    "My transformers from part 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f459edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# The CorrelatedFeaturesRemover class inherits from the sklearn.base classes \n",
    "# (BaseEstimator, TransformerMixin). This makes it compatible with \n",
    "# scikit-learnâ€™s Pipelines\n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    # initializer \n",
    "    def __init__(self, percentage_treshold):\n",
    "        self.percentage_treshold = percentage_treshold\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        self.cols_to_drop_ = []\n",
    "        X_ = X.copy()\n",
    "        num_of_samples = len(X_)\n",
    "\n",
    "        for col in X_.columns:\n",
    "            temp = X_[col].value_counts().sort_values(ascending=False)\n",
    "            if (list(temp)[0]/num_of_samples) > self.percentage_treshold[0]:\n",
    "                self.cols_to_drop_.append(col)\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X2 = X.copy()\n",
    "        X2.drop(self.cols_to_drop_, axis=1, inplace=True)\n",
    "        return X2\n",
    "\n",
    "class ReplaceOutliers(BaseEstimator, TransformerMixin):\n",
    "    # initializer \n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X2 = X.copy()\n",
    "        for col in X2.columns:\n",
    "            col_mean = np.mean(X2[col])\n",
    "            col_std = np.std(X2[col])\n",
    "            col_tres = col_std * self.factor[0]\n",
    "            X2[col] = X2[col].apply(lambda x: x if np.abs(x)<col_tres else col_tres*x/np.abs(x))\n",
    "        return X2\n",
    "    \n",
    "class CorrelatedFeaturesRemover(BaseEstimator, TransformerMixin):\n",
    "    # initializer \n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def reduce_correlated_features(self, X):\n",
    "        X_ = X.copy()\n",
    "        # if X is not DataFrame we have to make DataFrame\n",
    "        if type(X_)!=type(pd.DataFrame()):\n",
    "            X_ = pd.DataFrame(X_, columns=['f'+str(i) for i in range(X_.shape[1])])\n",
    "        run = True\n",
    "        while run:\n",
    "            corr = X_.corr()\n",
    "            l = len(corr)\n",
    "            for i in range(len(corr)):\n",
    "                corr.iloc[i,i]=0\n",
    "            sorted_features = np.max(corr).sort_values(ascending=False)\n",
    "            if sorted_features[0]>self.factor[0]:\n",
    "                feat_to_drop = sorted_features.index[0]\n",
    "                X_.drop([feat_to_drop], axis=1, inplace=True)\n",
    "            else:\n",
    "                run = False\n",
    "        return X_\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        X_ = self.reduce_correlated_features(X)\n",
    "        self.features_ = X_.columns\n",
    "        # return transformer object\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X_ = X.copy()\n",
    "        # if X is not DataFrame we have to make DataFrame\n",
    "        if type(X_)!=type(pd.DataFrame()):\n",
    "            X_ = pd.DataFrame(X_, columns=['f'+str(i) for i in range(X_.shape[1])])\n",
    "        if len(self.features_)>0:\n",
    "            X_ = X_[self.features_]\n",
    "            # return the dataframe with the specified features\n",
    "            return X_\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28050e8d",
   "metadata": {},
   "source": [
    "Read best models from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "915a5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('part4_best_ridge_model.pickle', 'rb') as f:\n",
    "            best_ridge_model = pickle.load(f)\n",
    "\n",
    "with open('part4_best_logistic_model.pickle', 'rb') as f:\n",
    "            best_logistic_model = pickle.load(f)\n",
    "\n",
    "with open('part4_best_mlp_model.pickle', 'rb') as f:\n",
    "            best_mlp_model = pickle.load(f)\n",
    "\n",
    "with open('part4_best_rf_model.pickle', 'rb') as f:\n",
    "            best_rf_model = pickle.load(f)\n",
    "\n",
    "with open('part4_best_svc_model.pickle', 'rb') as f:\n",
    "            best_svc_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a53eb50",
   "metadata": {},
   "source": [
    "Prepare indexes of training and testing sets for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "299aa348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining training and testing sets 90% / 10%\n",
    "train_X = X_all.loc[df['fold']!=10].copy()\n",
    "train_df = df.loc[df['fold']!=10].copy()\n",
    "train_Y = Y.loc[train_X.index].copy()\n",
    "test_X = X_all.loc[df['fold']==10].copy()\n",
    "test_X = Y.loc[test_X.index].copy()\n",
    "\n",
    "# generating 3 groups for cross validation\n",
    "cv_groups = []\n",
    "for i in range(1, 10, 3):\n",
    "    a , b, c = i, i+1, i+2\n",
    "    temp_train_X = train_X.loc[(train_df['fold']!=a) & (train_df['fold']!=b) & (train_df['fold']!=c)].copy()\n",
    "    temp_test_X = train_X.loc[(train_df['fold']==a) | (train_df['fold']==b) | (train_df['fold']==c)].copy()\n",
    "    cv_groups.append((temp_train_X.index, temp_test_X.index))\n",
    "    \n",
    "# defining 10 groups for corss validation\n",
    "cv_groups_10_fold = []\n",
    "for i in range(1, 11):\n",
    "    temp_train_X = X_all.loc[df['fold']!=i]\n",
    "    temp_test_X = X_all.loc[df['fold']==i]\n",
    "    cv_groups_10_fold.append((temp_train_X.index, temp_test_X.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71cf02",
   "metadata": {},
   "source": [
    "We can see that the predictions aren't the same so we can expect that combining them into one system can give better results then those from individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1192904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('ridge', best_ridge_model), ('lr', best_logistic_model),\n",
    "                                    ('mlp', best_mlp_model), ('rf', best_rf_model),\n",
    "                                    ('svc', best_svc_model)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a59bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67498138 0.71771553 0.73536585]\n",
      "0.7093542571795486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(eclf, X_all, Y, cv=cv_groups, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b9b89b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75143184 0.72184685 0.63351351 0.74242424 0.79487179 0.74848117\n",
      " 0.75536993 0.71588089 0.78186275 0.78136201]\n",
      "0.7427044982303604\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(eclf, X_all, Y, cv=cv_groups_10_fold, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a965e61b",
   "metadata": {},
   "source": [
    "Voting Classifier with voting parameter set to 'soft' uses the models predicted probabilities. Ridge classifier don't support this functionality so we can not use it this way. If we want SVC to return predicted probability we need to set its parameter 'probability' to True. We will do it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf3329c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('dc', DropColumns(percentage_treshold=[0.9])),\n",
       "  ('cfr', CorrelatedFeaturesRemover(factor=[0.97])),\n",
       "  ('ro', ReplaceOutliers(factor=[50])),\n",
       "  ('scaler', 'passthrough'),\n",
       "  ('qt', QuantileTransformer(output_distribution='normal', random_state=44)),\n",
       "  ('clf', SVC(C=1.467799267622069, random_state=44))],\n",
       " 'verbose': False,\n",
       " 'dc': DropColumns(percentage_treshold=[0.9]),\n",
       " 'cfr': CorrelatedFeaturesRemover(factor=[0.97]),\n",
       " 'ro': ReplaceOutliers(factor=[50]),\n",
       " 'scaler': 'passthrough',\n",
       " 'qt': QuantileTransformer(output_distribution='normal', random_state=44),\n",
       " 'clf': SVC(C=1.467799267622069, random_state=44),\n",
       " 'dc__percentage_treshold': [0.9],\n",
       " 'cfr__factor': [0.97],\n",
       " 'ro__factor': [50],\n",
       " 'qt__copy': True,\n",
       " 'qt__ignore_implicit_zeros': False,\n",
       " 'qt__n_quantiles': 1000,\n",
       " 'qt__output_distribution': 'normal',\n",
       " 'qt__random_state': 44,\n",
       " 'qt__subsample': 100000,\n",
       " 'clf__C': 1.467799267622069,\n",
       " 'clf__break_ties': False,\n",
       " 'clf__cache_size': 200,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__coef0': 0.0,\n",
       " 'clf__decision_function_shape': 'ovr',\n",
       " 'clf__degree': 3,\n",
       " 'clf__gamma': 'scale',\n",
       " 'clf__kernel': 'rbf',\n",
       " 'clf__max_iter': -1,\n",
       " 'clf__probability': False,\n",
       " 'clf__random_state': 44,\n",
       " 'clf__shrinking': True,\n",
       " 'clf__tol': 0.001,\n",
       " 'clf__verbose': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svc_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e497a6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('dc', DropColumns(percentage_treshold=[0.9])),\n",
       "                ('cfr', CorrelatedFeaturesRemover(factor=[0.97])),\n",
       "                ('ro', ReplaceOutliers(factor=[50])), ('scaler', 'passthrough'),\n",
       "                ('qt',\n",
       "                 QuantileTransformer(output_distribution='normal',\n",
       "                                     random_state=44)),\n",
       "                ('clf',\n",
       "                 SVC(C=1.467799267622069, probability=True, random_state=44))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svc_model.set_params(clf__probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec48fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf2 = VotingClassifier(estimators=[('lr', best_logistic_model),\n",
    "                                    ('mlp', best_mlp_model), ('rf', best_rf_model),\n",
    "                                    ('svc', best_svc_model)],\n",
    "                         voting='soft',\n",
    "                         n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58213548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67609829 0.71516915 0.7199187 ]\n",
      "0.7037287130074286\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(eclf2, X_all, Y, cv=cv_groups, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85176e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73310424 0.72635135 0.63891892 0.75656566 0.80555556 0.74848117\n",
      " 0.76610979 0.71091811 0.78921569 0.7921147 ]\n",
      "0.7467335168076312\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(eclf2, X_all, Y, cv=cv_groups_10_fold, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb40cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "eclf3 = StackingClassifier(estimators=[('lr', best_logistic_model),\n",
    "                                    ('mlp', best_mlp_model), ('rf', best_rf_model),\n",
    "                                    ('svc', best_svc_model)], final_estimator=LogisticRegression(), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e39ef54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67237528 0.69734449 0.72398374]\n",
      "0.6979011693226896\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(eclf3, X_all, Y, cv=cv_groups, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "089845bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72852234 0.7027027  0.62702703 0.75959596 0.79273504 0.72660996\n",
      " 0.76610979 0.69851117 0.79534314 0.77419355]\n",
      "0.7371350669476451\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(eclf3, X_all, Y, cv=cv_groups_10_fold, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c47f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf4 = StackingClassifier(estimators=[('lr', best_logistic_model),\n",
    "                                    ('mlp', best_mlp_model), ('rf', best_rf_model),\n",
    "                                    ('svc', best_svc_model)],\n",
    "                           final_estimator=RandomForestClassifier(random_state=44, n_jobs=-1),\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7b4ee1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6827997  0.67806475 0.71666667]\n",
      "0.6925103732148302\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(eclf4, X_all, Y, cv=cv_groups, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98bbf643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71134021 0.73085586 0.63783784 0.74343434 0.78205128 0.71931956\n",
      " 0.74821002 0.71960298 0.79166667 0.78136201]\n",
      "0.7365680763309795\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(eclf4, X_all, Y, cv=cv_groups_10_fold, n_jobs=-1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76479e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_test",
   "language": "python",
   "name": "tensorflow_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
