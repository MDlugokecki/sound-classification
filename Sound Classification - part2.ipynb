{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cef3795",
   "metadata": {},
   "source": [
    "<h1>Sound Classification - part 2</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982adee2",
   "metadata": {},
   "source": [
    "In this part we will add new ML models and compare their perfomance. We will select 5 the most promising and check how hyperparameters tuning can improve their performance.</br>\n",
    "Let's start from importing required libraries and reading metadata file and other data saved in part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ca5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 500\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b9048c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "      <th>channel_count</th>\n",
       "      <th>sampling_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>2</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>2</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>2</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>2</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>2</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  channel_count  sampling_rate  \n",
       "0          dog_bark              2          44100  \n",
       "1  children_playing              2          44100  \n",
       "2  children_playing              2          44100  \n",
       "3  children_playing              2          44100  \n",
       "4  children_playing              2          44100  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading saved X (features) and Y (labels) from files\n",
    "with open('part1_X.pickle', 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "with open('part1_Y.pickle', 'rb') as f:\n",
    "            Y = pickle.load(f)\n",
    "\n",
    "# read metadata writen to file in part 1\n",
    "with open('part1_df.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b005bc",
   "metadata": {},
   "source": [
    "From this part we will split out dataset on the training set and testing set. As test set we will hold fold10. Other folds will be used for traning and cross validation. As we want to keep original 10 folds data separation we need to write custom function for 9 folds cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23ef196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X on train and test sets\n",
    "train_X = X.loc[df['fold']!=10]\n",
    "train_Y = Y.loc[df['fold']!=10]\n",
    "test_X = X.loc[df['fold']==10]\n",
    "test_Y = Y.loc[df['fold']==10]\n",
    "\n",
    "### create scaled features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit_transform() returns numpy.ndarray, if we want to keep indexes and column names, we do it like this\n",
    "train_X_scaled = pd.DataFrame(scaler.fit_transform(train_X), index=train_X.index, columns=train_X.columns)\n",
    "# we fit scaler only with train data and transform test data using fitted scaler\n",
    "test_X_scaled = pd.DataFrame(scaler.transform(test_X), index=test_X.index, columns=test_X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f2d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our cross_val function similarly to my_cross_val_using_10_folds from part 1\n",
    "def my_cross_val_using_9_folds(clf, X, data):\n",
    "    test_score = []\n",
    "    train_score = []\n",
    "    if len(X.index) != len(data.index):\n",
    "        print(\"Indexes of X and data are not the same length!!!\")\n",
    "        return test_score, train_score\n",
    "    if (X.index != data.index).any():\n",
    "        print(\"Indexes of X and data are not equal!!!\")\n",
    "        return test_score, train_score\n",
    "    for i in range(1,10):\n",
    "        X_train = X.loc[data['fold']!=i]\n",
    "        Y_train = data.loc[data['fold']!=i]['class']\n",
    "        X_test = X.loc[data['fold']==i]\n",
    "        Y_test = data.loc[data['fold']==i]['class']\n",
    "        clf.fit(X_train, Y_train)\n",
    "        Y_pred = clf.predict(X_test)\n",
    "        temp = np.sum(Y_pred==Y_test)/len(Y_test)\n",
    "        test_score.append(temp)\n",
    "        Y_pred = clf.predict(X_train)\n",
    "        temp = np.sum(Y_pred==Y_train)/len(Y_train)\n",
    "        train_score.append(temp)\n",
    "    return test_score, train_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4286793",
   "metadata": {},
   "source": [
    "We will evaluate our models with our new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84e44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create dicts for scores\n",
    "score_table_unscaled = {}\n",
    "score_table_scaled = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039266d",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b91907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree average score - X unscaled:  0.5005973715651135\n",
      "Decision Tree average score - X scaled:  0.5005973715651135\n"
     ]
    }
   ],
   "source": [
    "### create decision tree classifier and evaluate it\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc_clf = DecisionTreeClassifier(random_state=44)\n",
    "\n",
    "# unscaled features\n",
    "dtc_clf.fit(train_X, train_Y)\n",
    "Y_pred = dtc_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_unscaled['Decision Tree'] = score\n",
    "print('Decision Tree average score - X unscaled: ', score)\n",
    "\n",
    "# scaled features\n",
    "dtc_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = dtc_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_scaled['Decision Tree'] = score\n",
    "print('Decision Tree average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa283f0",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422b3fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN average score - X unscaled:  0.5244922341696535\n",
      "KNN average score - X scaled:  0.5770609318996416\n"
     ]
    }
   ],
   "source": [
    "### create KNN classifier and evaluate it\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "# unscaled features\n",
    "knn_clf.fit(train_X, train_Y)\n",
    "Y_pred = knn_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_unscaled['KNN'] = score\n",
    "print('KNN average score - X unscaled: ', score)\n",
    "\n",
    "# scaled features\n",
    "knn_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = knn_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_scaled['KNN'] = score\n",
    "print('KNN average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f0675",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77d3d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest average score - X unscaled:  0.7574671445639187\n",
      "Random Forest average score - X scaled:  0.7562724014336918\n"
     ]
    }
   ],
   "source": [
    "### create Random Forest classifier and evaluate it\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1, random_state=44, n_estimators=500)\n",
    "\n",
    "# unscaled features\n",
    "rf_clf.fit(train_X, train_Y)\n",
    "Y_pred = rf_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_unscaled['Random Forest'] = score\n",
    "print('Random Forest average score - X unscaled: ', score)\n",
    "\n",
    "# scaled features\n",
    "rf_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = rf_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_scaled['Random Forest'] = score\n",
    "print('Random Forest average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e6efe8",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c08faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM average score - X unscaled:  0.3727598566308244\n",
      "SVM average score - X scaled:  0.7706093189964157\n"
     ]
    }
   ],
   "source": [
    "### create Support Vector Machines classifier and evaluate it\n",
    "from sklearn.svm import SVC\n",
    "svc_clf = SVC(random_state=44)\n",
    "\n",
    "# unscaled features\n",
    "svc_clf.fit(train_X, train_Y)\n",
    "Y_pred = svc_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_unscaled['SVM'] = score\n",
    "print('SVM average score - X unscaled: ', score)\n",
    "\n",
    "# scaled features\n",
    "svc_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = svc_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_scaled['SVM'] = score\n",
    "print('SVM average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b14de",
   "metadata": {},
   "source": [
    "Zero Rate Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e045b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero R average score - X unscaled:  0.1111111111111111\n",
      "Zero R average score - X scaled:  0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "### create Zero R classifier and evaluate it\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "# unscaled features\n",
    "dummy_clf.fit(train_X, train_Y)\n",
    "Y_pred = dummy_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_unscaled['Zero R'] = score\n",
    "print('Zero R average score - X unscaled: ', score)\n",
    "\n",
    "# scaled features\n",
    "dummy_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = dummy_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_scaled['Zero R'] = score\n",
    "print('Zero R average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b73ed0",
   "metadata": {},
   "source": [
    "Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4bcb3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge average score - X unscaled:  0.6881720430107527\n",
      "Ridge average score - X scaled:  0.6821983273596177\n"
     ]
    }
   ],
   "source": [
    "### create Ridge classifier and evaluate it\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier(random_state=44)\n",
    "\n",
    "# unscaled features\n",
    "ridge_clf.fit(train_X, train_Y)\n",
    "Y_pred = ridge_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_unscaled['Ridge'] = score\n",
    "print('Ridge average score - X unscaled: ', score)\n",
    "\n",
    "# scaled features\n",
    "ridge_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = ridge_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_scaled['Ridge'] = score\n",
    "print('Ridge average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d6caf",
   "metadata": {},
   "source": [
    "Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3faa562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression average score - X unscaled:  0.5651135005973715\n",
      "Logistic Regression average score - X scaled:  0.6953405017921147\n"
     ]
    }
   ],
   "source": [
    "### create Logistic Regression classifier and evaluate it\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression(random_state=44)\n",
    "\n",
    "# unscaled features\n",
    "lr_clf.fit(train_X, train_Y)\n",
    "Y_pred = lr_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_unscaled['Logistic Regression'] = score\n",
    "print('Logistic Regression average score - X unscaled: ', score)\n",
    "\n",
    "# scaled features\n",
    "lr_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = lr_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_scaled['Logistic Regression'] = score\n",
    "print('Logistic Regression average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e02a8c",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5523dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD average score - X unscaled:  0.4862604540023895\n",
      "SGD average score - X scaled:  0.5985663082437276\n"
     ]
    }
   ],
   "source": [
    "### create SGD classifier and evaluate it\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(n_jobs=-1, random_state=44)\n",
    "\n",
    "# unscaled features\n",
    "sgd_clf.fit(train_X, train_Y)\n",
    "Y_pred = sgd_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_unscaled['SGD'] = score\n",
    "print('SGD average score - X unscaled: ', score)\n",
    "\n",
    "# scaled features\n",
    "sgd_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = sgd_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_scaled['SGD'] = score\n",
    "print('SGD average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78897182",
   "metadata": {},
   "source": [
    "Passive Agressive Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf024678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passive Agressive average score - X unscaled:  0.5232974910394266\n",
      "Passive Agressive average score - X scaled:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "### create Passive Agressive classifier and evaluate it\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "pac_clf = PassiveAggressiveClassifier(n_jobs=-1, random_state=44)\n",
    "\n",
    "# unscaled features\n",
    "pac_clf.fit(train_X, train_Y)\n",
    "Y_pred = pac_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_unscaled['Passive Agressive'] = score\n",
    "print('Passive Agressive average score - X unscaled: ', score)\n",
    "\n",
    "# scaled features\n",
    "pac_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = pac_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_scaled['Passive Agressive'] = score\n",
    "print('Passive Agressive average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c67576",
   "metadata": {},
   "source": [
    "Nearest Centroid Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25e67151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Centroid average score - X unscaled:  0.2855436081242533\n",
      "Nearest Centroid average score - X scaled:  0.5053763440860215\n"
     ]
    }
   ],
   "source": [
    "### create Nearest Centroid classifier and evaluate it\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "nc_clf = NearestCentroid()\n",
    "\n",
    "# unscaled features\n",
    "nc_clf.fit(train_X, train_Y)\n",
    "Y_pred = nc_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_unscaled['Nearest Centroid'] = score\n",
    "print('Nearest Centroid average score - X unscaled: ', score)\n",
    "\n",
    "# scaled features\n",
    "nc_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = nc_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_scaled['Nearest Centroid'] = score\n",
    "print('Nearest Centroid average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9874234a",
   "metadata": {},
   "source": [
    "Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d2c6d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP average score - X unscaled:  0.6547192353643967\n",
      "MLP average score - X scaled:  0.7359617682198327\n"
     ]
    }
   ],
   "source": [
    "### create Multi-Layer Perceptron classifier and evaluate it\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_clf = MLPClassifier(random_state=44)\n",
    "\n",
    "# unscaled features\n",
    "mlp_clf.fit(train_X, train_Y)\n",
    "Y_pred = mlp_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_unscaled['MLP'] = score\n",
    "print('MLP average score - X unscaled: ', score)\n",
    "\n",
    "# scaled features\n",
    "mlp_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = mlp_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_scaled['MLP'] = score\n",
    "print('MLP average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c65ec517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_X_unscaled</th>\n",
       "      <th>base_X_scaled</th>\n",
       "      <th>MAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.372760</td>\n",
       "      <td>0.770609</td>\n",
       "      <td>0.770609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.757467</td>\n",
       "      <td>0.756272</td>\n",
       "      <td>0.757467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.654719</td>\n",
       "      <td>0.735962</td>\n",
       "      <td>0.735962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.565114</td>\n",
       "      <td>0.695341</td>\n",
       "      <td>0.695341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.682198</td>\n",
       "      <td>0.688172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive Agressive</th>\n",
       "      <td>0.523297</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.486260</td>\n",
       "      <td>0.598566</td>\n",
       "      <td>0.598566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.524492</td>\n",
       "      <td>0.577061</td>\n",
       "      <td>0.577061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Centroid</th>\n",
       "      <td>0.285544</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.505376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.500597</td>\n",
       "      <td>0.500597</td>\n",
       "      <td>0.500597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero R</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     base_X_unscaled  base_X_scaled       MAX\n",
       "SVM                         0.372760       0.770609  0.770609\n",
       "Random Forest               0.757467       0.756272  0.757467\n",
       "MLP                         0.654719       0.735962  0.735962\n",
       "Logistic Regression         0.565114       0.695341  0.695341\n",
       "Ridge                       0.688172       0.682198  0.688172\n",
       "Passive Agressive           0.523297       0.666667  0.666667\n",
       "SGD                         0.486260       0.598566  0.598566\n",
       "KNN                         0.524492       0.577061  0.577061\n",
       "Nearest Centroid            0.285544       0.505376  0.505376\n",
       "Decision Tree               0.500597       0.500597  0.500597\n",
       "Zero R                      0.111111       0.111111  0.111111"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_table = pd.concat([pd.Series(score_table_unscaled, name='base_X_unscaled'),\n",
    "                         pd.Series(score_table_scaled, name='base_X_scaled')], axis=1)\n",
    "score_table['MAX'] = score_table.max(axis=1)\n",
    "score_table.to_csv('part2_score_table.csv')\n",
    "score_table.sort_values(by='MAX', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31ebe0",
   "metadata": {},
   "source": [
    "Our TOP 5 best performing ML classifiers are: Support Vector Machine, Random Forest, Multi-Layer Perceptron, Logostic Regression, Ridge.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a506f1",
   "metadata": {},
   "source": [
    "We will make fine tuning of hyperparameters using predefined 9 folds split. We can't use sklearn grid_serch_CV() but we will write our own function. We will need 2 auxiliary functions to generate all possible combinations of given parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c457c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function rewrite given list of dictionaries generating new list which elements are all possibe combinations of\n",
    "# element in given list and elements in arg 'value' which is also a list\n",
    "def add_param(name, values, my_list=[]):\n",
    "    new_list = []\n",
    "    if len(my_list)==0:\n",
    "        my_list.append({})\n",
    "    for l in my_list:\n",
    "        for value in values:\n",
    "            temp_my_dict = l.copy()\n",
    "            temp_my_dict[name]=value\n",
    "            new_list.append(temp_my_dict)\n",
    "    return new_list\n",
    "\n",
    "# this function generate all possible combinations of parameters given in arg params, arg params is a list of dictionaries\n",
    "# accorging to the approach taken in sklearn library class GridSearchCV\n",
    "def make_list_of_parameters_dictionary(params):\n",
    "    list_of_parameters = []\n",
    "    for d in params:\n",
    "        item_list = []\n",
    "        for name, values in d.items():\n",
    "            item_list = add_param(name, values, item_list)\n",
    "        list_of_parameters.extend(item_list)\n",
    "    return list_of_parameters\n",
    "    \n",
    "from os.path import exists\n",
    "\n",
    "# our grid search function generates all possible combinations of parameters given in 'params' and performs cross validation\n",
    "# for given classifier setted with each parameters combination, returning best set of parameters accorging to 'accuracy' metrics\n",
    "# return set of parameters is a full set of model's parameters\n",
    "def my_grid_search_cross_validation(clf, X, df, params):\n",
    "    best_score = 0\n",
    "    best_params = {}\n",
    "    start = time.time()\n",
    "    i = 1\n",
    "    list_of_parameters = make_list_of_parameters_dictionary(params)\n",
    "    l = len(list_of_parameters)\n",
    "    df2 = df.loc[df['fold']!=10]\n",
    "    for p in list_of_parameters:\n",
    "        clf.set_params(**p)\n",
    "        test_score, train_score = my_cross_val_using_9_folds(clf, X, df2)\n",
    "        mean_test_score = np.mean(test_score)\n",
    "        mean_train_score = np.mean(train_score)\n",
    "        if mean_test_score > best_score:\n",
    "            best_params = clf.get_params()\n",
    "            best_score = mean_test_score\n",
    "        print('\\n',i,'/',l,' duration: ',time.time()-start, ' best score: ',best_score)\n",
    "        print('Test score:    ', mean_test_score)\n",
    "        print('Train score:   ', mean_train_score)\n",
    "        print(p)\n",
    "        i += 1\n",
    "        if exists('stop.txt'):\n",
    "            print('Proces przerwany.')\n",
    "            break\n",
    "    print('Best score: ', best_score)\n",
    "    print('Best params: ', best_params)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cfb521",
   "metadata": {},
   "source": [
    "<h3>Tuning Logistic Regression model</h3>\n",
    "This model performs better with scaled feaures that's why we will use X_scaled.</br>\n",
    "Searching of optimal hyperparameters values is iterative process. We will try same initial range of parameters values. According to results of first run we will change the range or step of the values in next runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6544c080",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'solver': ['liblinear'],\n",
    "        'penalty': ['l1'],\n",
    "#         'tol': [0.01],\n",
    "#     },\n",
    "#     {\n",
    "#             'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "#         'solver': ['liblinear', 'saga'],\n",
    "#         'penalty': ['l2', 'l1'],\n",
    "        'tol': [1e-2],\n",
    "        'C': [0.5],\n",
    "#         'fit_intercept': [True, False],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "#         'max_iter': [100, 80, 120],\n",
    "#         'l1_ratio': [0.1, 0.5, 0.9] # if penalty = 'elasticnet'\n",
    "#     },\n",
    "#     {\n",
    "#      'penalty': ['elasticnet', 'l1', 'l2', 'none'],\n",
    "#      'tol': [1e-7, 1e-6, 1e-5],\n",
    "#      'C': [0.04, 0.05, 0.6],\n",
    "#      'fit_intercept': [True, False],\n",
    "#      'class_weight': [None, 'balanced'],\n",
    "#      'solver': ['saga'],\n",
    "#      'max_iter': [80, 90, 100]\n",
    "    }\n",
    "    ]\n",
    "\n",
    "# parameters that we are sure will be defined here and set model with them before starting the grid search process\n",
    "constant_params = {'random_state': 44, 'dual': False, 'multi_class':'auto', 'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "948abaab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(n_jobs=-1, random_state=44)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.set_params(**constant_params)\n",
    "# logostic_regression_best_params = my_grid_search_cross_validation(lr_clf, train_X_scaled, df, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c4d7b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved best params\n",
    "logostic_regression_best_params = {'C': 0.5, 'class_weight': None, 'dual': False, 'fit_intercept': True,\n",
    "                                   'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto',\n",
    "                                   'n_jobs': -1, 'penalty': 'l1', 'random_state': 44, 'solver': 'liblinear',\n",
    "                                   'tol': 0.01, 'verbose': 0, 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35b03a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression average score - X scaled:  0.7168458781362007\n"
     ]
    }
   ],
   "source": [
    "score_table_tuned = {}\n",
    "\n",
    "lr_clf.set_params(**logostic_regression_best_params)\n",
    "lr_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = lr_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_tuned['Logistic Regression'] = score\n",
    "print('Logistic Regression average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4148c92d",
   "metadata": {},
   "source": [
    "<h3>Tuning Ridge model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f51e8f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'solver': ['auto'],\n",
    "        'alpha': [x for x in range(80, 100)],\n",
    "        'fit_intercept': [True],#, False],\n",
    "        'class_weight': [None],#, 'balanced'],\n",
    "        'positive': [False]\n",
    "#     },\n",
    "#     {\n",
    "#         'solver': ['lbfgs'],\n",
    "#         'alpha': [0.01, 0.1, 1, 10, 100],\n",
    "#         'fit_intercept': [True, False],\n",
    "#         'class_weight': [None, 'balanced'],\n",
    "#         'positive': [True]\n",
    "    }\n",
    "    ]\n",
    "constant_params = {'random_state': 44}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6650f1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(random_state=44)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.set_params(**constant_params)\n",
    "# ridge_best_params = my_grid_search_cross_validation(ridge_clf, train_X, df, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03f79042",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_best_params = {'alpha': 92, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None,\n",
    "                     'normalize': 'deprecated', 'positive': False, 'random_state': 44, 'solver': 'auto', 'tol': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc4732e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge average score - X scaled:  0.6953405017921147\n"
     ]
    }
   ],
   "source": [
    "ridge_clf.set_params(**ridge_best_params)\n",
    "ridge_clf.fit(train_X, train_Y)\n",
    "Y_pred = ridge_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_tuned['Ridge'] = score\n",
    "print('Ridge average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2801b4",
   "metadata": {},
   "source": [
    "<h3>Tuning MLP model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a43f4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'hidden_layer_sizes': [(1000,)],\n",
    "        'activation': ['relu'], #, 'identity', 'logistic', 'tanh'],\n",
    "        'alpha': [0.0001],\n",
    "        'batch_size': [200],\n",
    "        'learning_rate': ['constant'], #, 'invscaling', 'adaptive'],\n",
    "        'early_stopping': [False, True]\n",
    "    }\n",
    "    ]\n",
    "constant_params = {'random_state': 44, 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01ef982f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(random_state=44)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_clf.set_params(**constant_params)\n",
    "# mlp_best_params = my_grid_search_cross_validation(mlp_clf, train_X_scaled, df, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "602a2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_best_params = {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 200, 'beta_1': 0.9, 'beta_2': 0.999,\n",
    "                   'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (1000,), 'learning_rate': 'constant',\n",
    "                   'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 200, 'momentum': 0.9, 'n_iter_no_change': 10,\n",
    "                   'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 44, 'shuffle': True, 'solver': 'adam',\n",
    "                   'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af544a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP average score - X scaled:  0.7538829151732378\n"
     ]
    }
   ],
   "source": [
    "mlp_clf.set_params(**mlp_best_params)\n",
    "mlp_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = mlp_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_tuned['MLP'] = score\n",
    "print('MLP average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86869f",
   "metadata": {},
   "source": [
    "<h3>Tuning Random Forest classifier model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da24898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'n_estimators': [550],\n",
    "        'criterion': [\"entropy\"],\n",
    "        'max_depth': [None],\n",
    "        'min_samples_split': [2],\n",
    "        'min_samples_leaf': [2],\n",
    "        'max_features': [\"auto\"],\n",
    "        'max_leaf_nodes': [None],\n",
    "        'class_weight': ['balanced_subsample']\n",
    "    },\n",
    "    {\n",
    "        'n_estimators': [575, 600], #[x for x in range(50, 1000, 50)],\n",
    "        'criterion': ['gini', \"entropy\"],\n",
    "        'max_depth': [None], #[None, 5, 10, 15, 20, 25, 30]\n",
    "        'min_samples_split': [2, 3, 4, 5], #, 7, 8, 9, 10]\n",
    "        'min_samples_leaf': [1, 2, 3], #, 2, 3, 4, 5, 6]\n",
    "        'max_features': [\"auto\"], #, None, \"log2\"]\n",
    "        'max_leaf_nodes': [None], #, 5, 10, 20, 50, 100]\n",
    "        'class_weight': ['balanced_subsample']\n",
    "    }\n",
    "    ]\n",
    "constant_params = {'random_state': 44, 'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b971795b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=44)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.set_params(**constant_params)\n",
    "# rf_best_params = my_grid_search_cross_validation(rf_clf, train_X, df, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5095f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_params = {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced_subsample', 'criterion': 'entropy',\n",
    "                  'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None,\n",
    "                  'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 2,\n",
    "                  'min_weight_fraction_leaf': 0.0, 'n_estimators': 550, 'n_jobs': -1, 'oob_score': False,\n",
    "                  'random_state': 44, 'verbose': 0, 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9579b955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest average score - X scaled:  0.7634408602150538\n"
     ]
    }
   ],
   "source": [
    "rf_clf.set_params(**rf_best_params)\n",
    "rf_clf.fit(train_X, train_Y)\n",
    "Y_pred = rf_clf.predict(test_X)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_tuned['Random Forest'] = score\n",
    "print('Random Forest average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f911e",
   "metadata": {},
   "source": [
    "<h3> Tuning SVM Classifier </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a8df158",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'C': [5], #[x/10 for x in range(40, 60)] #[3, 4, 5, 6, 7, 8, 9]\n",
    "        'kernel': ['rbf'], #['linear', 'poly', 'rbf', 'sigmoid']\n",
    "        'gamma': ['scale', 0.0001, 0.0003, 0.001, 0.002, 0.003, 0.004, 0.005], #, 'auto'], \n",
    "        'tol': [1e-2],\n",
    "        'class_weight': [None], #, 'balanced'],\n",
    "        'max_iter': [500], #, 1000, 2000, 5000],\n",
    "        'decision_function_shape': ['ovr'],\n",
    "    }]\n",
    "\n",
    "# parameters that we are sure will be defined here and set model with them before starting the grid search process\n",
    "constant_params = {'random_state': 44}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02493d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=44)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf.set_params(**constant_params)\n",
    "# svc_best_params_all_features = my_grid_search_cross_validation(svc_clf, train_X_scaled, df, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ada983ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_best_params = {'C': 5, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0,\n",
    "                   'decision_function_shape': 'ovo', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 500,\n",
    "                   'probability': False, 'random_state': 44, 'shrinking': True, 'tol': 0.01, 'verbose': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04097e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM average score - X scaled:  0.7622461170848268\n"
     ]
    }
   ],
   "source": [
    "svc_clf.set_params(**svc_best_params)\n",
    "svc_clf.fit(train_X_scaled, train_Y)\n",
    "Y_pred = svc_clf.predict(test_X_scaled)\n",
    "score = np.sum(Y_pred == test_Y)/len(test_Y)\n",
    "score_table_tuned['SVM'] = score\n",
    "print('SVM average score - X scaled: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79611a6d",
   "metadata": {},
   "source": [
    "Let's see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78cd82e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_X_unscaled</th>\n",
       "      <th>base_X_scaled</th>\n",
       "      <th>tuned</th>\n",
       "      <th>MAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.372760</td>\n",
       "      <td>0.770609</td>\n",
       "      <td>0.762246</td>\n",
       "      <td>0.770609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.757467</td>\n",
       "      <td>0.756272</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.763441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.654719</td>\n",
       "      <td>0.735962</td>\n",
       "      <td>0.753883</td>\n",
       "      <td>0.753883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.565114</td>\n",
       "      <td>0.695341</td>\n",
       "      <td>0.716846</td>\n",
       "      <td>0.716846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.682198</td>\n",
       "      <td>0.695341</td>\n",
       "      <td>0.695341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive Agressive</th>\n",
       "      <td>0.523297</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.486260</td>\n",
       "      <td>0.598566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.524492</td>\n",
       "      <td>0.577061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.577061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Centroid</th>\n",
       "      <td>0.285544</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.505376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.500597</td>\n",
       "      <td>0.500597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero R</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     base_X_unscaled  base_X_scaled     tuned       MAX\n",
       "SVM                         0.372760       0.770609  0.762246  0.770609\n",
       "Random Forest               0.757467       0.756272  0.763441  0.763441\n",
       "MLP                         0.654719       0.735962  0.753883  0.753883\n",
       "Logistic Regression         0.565114       0.695341  0.716846  0.716846\n",
       "Ridge                       0.688172       0.682198  0.695341  0.695341\n",
       "Passive Agressive           0.523297       0.666667       NaN  0.666667\n",
       "SGD                         0.486260       0.598566       NaN  0.598566\n",
       "KNN                         0.524492       0.577061       NaN  0.577061\n",
       "Nearest Centroid            0.285544       0.505376       NaN  0.505376\n",
       "Decision Tree               0.500597       0.500597       NaN  0.500597\n",
       "Zero R                      0.111111       0.111111       NaN  0.111111"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read score table\n",
    "score_table = pd.read_csv('part2_score_table.csv', index_col=0)\n",
    "\n",
    "# drop 'MAX' column\n",
    "score_table.drop(['MAX'], axis=1, inplace=True)\n",
    "\n",
    "# make new DataFrame using new  results\n",
    "score_table = pd.concat([score_table,\n",
    "                         pd.Series(score_table_tuned, name='tuned')],\n",
    "                        axis=1)\n",
    "\n",
    "# add new column with best result for each model\n",
    "score_table['MAX'] = score_table.max(axis=1)\n",
    "\n",
    "# save to file\n",
    "score_table.to_csv('part2_score_table_tuned.csv')\n",
    "\n",
    "# show sorted score table\n",
    "score_table.sort_values(by='MAX', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9d56c",
   "metadata": {},
   "source": [
    "In general adjusting hyperparameters improve models performance unless we overfit the model. In case of SVM model by changing the hyperparameters we have fittet the model better to train data but as it was performing better on train data it gets worse results on new data. It is called overfiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1398a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_test",
   "language": "python",
   "name": "tensorflow_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
